{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#!pip install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accomplishes the following goals:\n",
    "\n",
    "1. Creates a recommender class from scratch using collaborative filtering and jaccard similarity\n",
    "2. Creates a data class to load and manipulate the E-Corp data sets\n",
    "3. Loads and transforms E-Corp data; instantiates and trains item-item rec engine; generates, prints and saves recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Recommender Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(self, data, user_col, item_cols, cf_method='item', similarity='pearson'):\n",
    "        '''init Recommender class'''\n",
    "        self.data = data\n",
    "        self.user_col = user_col\n",
    "        self.item_cols = item_cols\n",
    "        self.cf_method = cf_method\n",
    "        self.similarity = similarity\n",
    "        self.similarity_matrix = []\n",
    "        self.user_scores = []\n",
    "        self.recs = []\n",
    "\n",
    "    def create_similarity_matrix(self):\n",
    "        '''creates correlation/similarity matrix for all items and stores result and self.similarity_matrix'''\n",
    "        self.similarity_matrix = self._create_empty_df(self.cf_method)\n",
    "        self._fill_similarity_matrix(self.similarity_matrix, self.similarity)\n",
    "\n",
    "    def score_users(self, users=None):\n",
    "        '''generates item ratings for each item for each user and stores result as self.user_scores'''\n",
    "        if not users:\n",
    "            # grab all users in data by default\n",
    "            users = self.data.loc[:,self.user_col]\n",
    "        cols = [self.user_col] + list(self.item_cols)\n",
    "        user_data = self.data.loc[:,cols].set_index(self.user_col)\n",
    "        self.user_scores = pd.DataFrame(index=users, columns=self.item_cols)\n",
    "        self.user_scores = self.data[self.item_cols].dot(self.similarity_matrix)\n",
    "                \n",
    "    def score_new_users(self, users, user_data):\n",
    "        '''generates item ratings for users passed in from external data set and stores result as self.user_scores'''\n",
    "        cols = [self.user_col] + list(self.item_cols)\n",
    "        self.user_scores = pd.DataFrame(index=user_data.index, columns=self.item_cols)\n",
    "        self.user_scores = user_data.loc[self.item_cols].dot(self.similarity_matrix)        \n",
    "                \n",
    "    def generate_recs(self, users=None, num_recs=5):\n",
    "        '''generates top num_rec recommendations for users and stores result as self.recs'''\n",
    "        if not users:\n",
    "            # grab all users in data by default\n",
    "            users = self.data.loc[:,self.user_col]\n",
    "        cols = ['Rec ' + str(x) for x in range(1,num_recs+1)] + ['Score ' + str(x) for x in range(1,num_recs+1)]\n",
    "        self.recs = pd.DataFrame(index=users, columns=cols)\n",
    "        progress_bar = tqdm(total = len(users), mininterval=5)\n",
    "        for user in users:\n",
    "            progress_bar.update()\n",
    "            sorted_items = self.user_scores.sort_values(by=user, ascending=False, axis=1).loc[user,:].index\n",
    "            for i in range(num_recs):\n",
    "                item = sorted_items[i]\n",
    "                item_col = cols[i]\n",
    "                score_col = cols[i+num_recs]\n",
    "                self.recs.loc[user, item_col] = item\n",
    "                self.recs.loc[user, score_col] = self.user_scores.loc[user, item]\n",
    "        self.recs.reset_index(inplace=True, drop=False)\n",
    "\n",
    "    def print_recs(self):\n",
    "        '''prints self.recs to stdout'''\n",
    "        print(self.recs)\n",
    "        \n",
    "    def save_recs(self, filename='recommendations', format='excel'):\n",
    "        '''saves self.recs to filename in specified format'''\n",
    "        if format == 'excel':\n",
    "            extension ='.xlsx'\n",
    "            self.recs.to_excel(filename + extension, index=False)\n",
    "        elif format == 'csv':\n",
    "            extension += '.csv'\n",
    "            self.recs.to_csv(filename + extension, index=False)\n",
    "        else:\n",
    "            raise ValueError('Invalid file format.  Please specify \"excel\" or \"csv\".')\n",
    "  \n",
    "    def _create_empty_df(self, cf_type):\n",
    "        '''creates and returns empty df with users or items as rows and columns'''\n",
    "        if cf_type == 'item':\n",
    "            labels = self.item_cols\n",
    "        elif cf_type == 'user':\n",
    "            labels = self.data[user_col]\n",
    "        else:\n",
    "            raise ValueError('Invalid collaborative filtering technique.  Please specify \"item\" or \"user\".')\n",
    "        return pd.DataFrame(index=labels, columns=labels)\n",
    "\n",
    "    def _fill_similarity_matrix(self, similarity_matrix, similarity):\n",
    "        '''calculates correlation between items using specified similarity and saves results in similarity_matrix\n",
    "           valid similarity types: jaccard, pearson, cosine'''\n",
    "        k=0\n",
    "        item_df = self.data[self.item_cols] \n",
    "        #print(item_df)\n",
    "        progress_bar = tqdm(total = similarity_matrix.shape[0], mininterval=5)\n",
    "        for i in range(similarity_matrix.shape[0]):\n",
    "            progress_bar.update()\n",
    "            similarity_matrix.ix[i,i] = 1.0\n",
    "            x = item_df.ix[:,i]\n",
    "            for j in range(i,similarity_matrix.shape[1]):\n",
    "                y = item_df.ix[:,j]\n",
    "                similarity_matrix.ix[i,j] = self._get_similarity(x, y, similarity)\n",
    "                similarity_matrix.ix[j,i] = similarity_matrix.ix[i, j]\n",
    "                \n",
    "    def _get_similarity(self, x, y, similarity):\n",
    "        '''calculated specified correlation between two vectors and returns result'''\n",
    "        if similarity == 'pearson':\n",
    "            return self._pearson_similarity(x, y)\n",
    "        elif similarity == 'jaccard':\n",
    "            return self._jaccard_similarity(x, y)\n",
    "        elif similarity == 'cosine':\n",
    "            return self._cosine_similarity(x, y)\n",
    "        else:\n",
    "            raise ValueError('Invalid similarity type.  Please specify \"cosine\", \"pearson\", or \"jaccard\".')\n",
    "        \n",
    "    def _pearson_similarity(self, x, y):\n",
    "        '''returns pearson correlation between x and y: covariance(x,y)/(std_dev(x)*std_dev(y))'''\n",
    "        #effective if data can be transformed to normal distribution \n",
    "        pass\n",
    "\n",
    "    def _jaccard_similarity(self, x, y):\n",
    "        '''returns jaccard correlation between x and y: |intsection(x,y)|/|union(x,y)|'''\n",
    "        #ideal for binary data, e.g. buy vs non-buy\n",
    "        nonzero_x = set(np.nonzero(x)[0])\n",
    "        nonzero_y = set(np.nonzero(y)[0])\n",
    "        intersection_size = len(nonzero_x.intersection(nonzero_y))\n",
    "        union_size = len(nonzero_x.union(nonzero_y))\n",
    "        if union_size == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return intersection_size/union_size\n",
    "\n",
    "    def _cosine_similarity(self, x, y):\n",
    "        '''returns cosine of angles between x and y'''\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        '''init Data class'''\n",
    "        self.data = None\n",
    "        \n",
    "    def load_data(self, filename, format='txt'):\n",
    "        '''loads data from excel, csv, tsv or txt file'''\n",
    "        if format == 'excel':\n",
    "            self.data = pd.read_excel(filename)\n",
    "        elif format == 'csv':\n",
    "            self.data = pd.read_csv(filename)\n",
    "        elif format == 'tsv':\n",
    "            self.data = pd.read_csv(filename, sep='\\t')\n",
    "        elif format == 'txt':\n",
    "            self.data = pd.read_table(filename)\n",
    "        else:\n",
    "            raise ValueError('Invalid file format. Please specify \"excel\",\"csv\",\"tsv\" or \"txt\".')\n",
    "    \n",
    "    def drop_small_orders(self, order_col = 'order_number', min_order_size=2):\n",
    "        '''drop orders from self.data that have min_order_size or less unique items in basket'''\n",
    "        self.data = self.data[self.data.groupby('order_number').order_number.transform(len) >= min_order_size]\n",
    "    \n",
    "    def expand_columns(self, columns=[]):\n",
    "        '''performs one-hot encoding on specified columns and appends them to self.data'''\n",
    "        dfs = []\n",
    "        dfs.append(self.data)\n",
    "        for col in columns:\n",
    "            dfs.append(pd.get_dummies(self.data[col], prefix=None, sparse=False))\n",
    "            self.data = pd.concat(dfs, axis=1)\n",
    "    \n",
    "    def drop_columns(self, columns=[]):\n",
    "        '''drops columns from self.data'''\n",
    "        self.data.drop(columns, axis=1, inplace=True)\n",
    "    \n",
    "    def consolidate_orders(self, order_col='order_number'):\n",
    "        '''consolidates each order in self.data into single record. Order number is maintained and all other columns summed.'''\n",
    "        data_cols = self.data.columns\n",
    "        data_cols.drop(order_col)\n",
    "        self.data = self.data.groupby(order_col).sum()[data_cols].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Data Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and_process_data = True\n",
    "get_columns = True\n",
    "run_rec_engine = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text file into DataFrame and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['order_number'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-14efbb4a04e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'l3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sku'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'brand'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate_orders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'order_number'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-8bca7476ef82>\u001b[0m in \u001b[0;36mconsolidate_orders\u001b[0;34m(self, order_col)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mdata_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mdata_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2906\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;31m# we skip the warning on Categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['order_number'] not in index\""
     ]
    }
   ],
   "source": [
    "# drop orders with few items, one-hot encode l3 category information, drop unnecessary columns and consolidate unique orders into single records\n",
    "if load_and_process_data:\n",
    "    data = Data()\n",
    "    data.load_data('/Users/sailalithasadhu/Desktop/DSDJ/Projects/ProductRecommendation/All Transations - 2 Weeks.txt', format = 'txt')\n",
    "    data.drop_small_orders(order_col = 'order_number', min_order_size = 20)\n",
    "    data.expand_columns(['l3'])\n",
    "    data.drop_columns(['l1','l2','l3','sku','brand'])\n",
    "    data.consolidate_orders(order_col='order_number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_columns:\n",
    "    user_col = 'order_number'\n",
    "    item_cols = list(data.data.columns)\n",
    "    item_cols.remove(user_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run recommendation engine and generate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_rec_engine:\n",
    "    rec_engine = Recommender(data.data, user_col=user_col, item_cols=item_cols, cf_method='item', similarity = 'jaccard')\n",
    "    rec_engine.create_similarity_matrix()\n",
    "    rec_engine.score_users()\n",
    "    rec_engine.generate_recs()\n",
    "    rec_engine.save_recs()\n",
    "    rec_engine.print_recs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
